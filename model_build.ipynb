{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "d2-4kT4PgODj",
    "outputId": "74b798f0-d053-4a67-c6b1-6e930c93f9fd"
   },
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "%matplotlib inline\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_directory = os.getcwd()\n",
    "print(f\"Current working directory: {current_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clinvar_conflicting.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV file from Jupyter Hub\n",
    "\n",
    "df = pd.read_csv('clinvar_conflicting.csv', encoding='ISO-8859-1', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m42CfsfG0St3"
   },
   "source": [
    "The info above indicates that the DataFrame has a total of 46 parameters (fields). Typically, it's best practice to examine the variables and begin cleaning the data. Without cleaning the data, feature selection and model generation will be highly inaccurate.\n",
    "\n",
    "Let's begin exploring our dataframe and focus on our first goal - data cleaning. Data cleaning typically involves examining null values, detecting outliers, and examining initial relationships between categorical and continuous variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dataframe with data type, nulls, & unique values\n",
    "\n",
    "var_df = pd.DataFrame(columns=['variable_name', 'data_type', 'missing_percentage', 'flag', 'unique_values_count'])\n",
    "\n",
    "missing_percentages = df.isnull().mean() * 100\n",
    "missing_percentages = missing_percentages.sort_values(ascending=False)\n",
    "\n",
    "# create variables and flag as numeric or categorial\n",
    "for col in df.columns:\n",
    "    data_type = df[col].dtype\n",
    "    missing_percentage = missing_percentages[col]\n",
    "    unique_values_count = df[col].nunique()\n",
    "    if data_type == 'int64' or data_type == 'float64':\n",
    "        flag = 'numeric'\n",
    "    else:\n",
    "        flag = 'categorical'\n",
    "    \n",
    "    # concat values obtained into a new dataframe called 'var_df'\n",
    "    var_df = pd.concat([var_df, pd.DataFrame({'variable_name': [col], 'data_type': [data_type], 'missing_percentage': [missing_percentage], 'flag': [flag], 'unique_values_count': [unique_values_count]})], ignore_index=True)\n",
    "    \n",
    "var_df.info()\n",
    "print(var_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort variables by missing percentage value\n",
    "var_df_sorted = var_df.sort_values(by='missing_percentage')\n",
    "var_df_sorted.reset_index(drop=True, inplace=True)\n",
    "\n",
    "var_df_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chart above shows the presence of columns with very high values of missing percentages. In fact, 9 of them have greater than 99.5% missing values, meaning less than 0.5% are actual non-null values in such columns.\n",
    "\n",
    "For the sake of this project, columns with > 99% missing values will be dropped. This will effectively drop the 9 columns at the bottom of the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_df = var_df_sorted.copy()\n",
    "\n",
    "# Set the threshold for missing values percentage and drop if necessary\n",
    "threshold = 99  \n",
    "var_df = var_df[var_df['missing_percentage'] <= threshold]\n",
    "\n",
    "var_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that columns have been removed, they must be removed again from the original 'df' dataframe. The chart above is a dataframe extracted from the initial dataframe for analysis. Calling 'df' dataframe below proves this point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the threshold for missing values percentage and drop\n",
    "\n",
    "threshold = 99  \n",
    "\n",
    "missing_percentages = df.isnull().mean() * 100\n",
    "columns_to_drop = missing_percentages[missing_percentages > threshold].index.tolist() \n",
    "\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our first set of columns have been dropped, we can begin examining the relationships between variables to better understand inconsistencies and errors in the data. A heat matrix will give us a good initial indication of correlations between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# filter numerical columns and create correlation heat matrix map\n",
    "numerical_columns = df.select_dtypes(include=['int64', 'float64'])\n",
    "corr_matrix = numerical_columns.corr() # calculate correlations\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, cmap='coolwarm', annot=True, fmt='.2f') # generate heat map\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heat matrix above shows the correlations between the numerical columns of the initial 'df' dataframe which are separated into another dataframe called 'numerical_columns'. Keep in mind that these may not end up being the final numerical columns in the dataframe. All columns must be analyzed first to accurately assign numeric and non-numeric values to each. As for now, the collected numerical columns above will serve as a good first step.\n",
    "\n",
    "OBSERVATION:\n",
    "\n",
    "There appears to be high correlations amongst the three Allele Frequency columns - AF_ESP, AF_EXAC, AF_TGP. These columns have the same theoretical value of allele frequency but are obtained from different databases. Allele frequency refers to the proportion of a specific allele within a population's gene pool, representing the prevalence of that genetic variant. Mutations can affect allele frequencies by introducing new alleles or altering the relative proportions of existing alleles in a population over time.\n",
    "\n",
    "The high correlations help prove this point. However, they also show that there is a discrepancy between the values of the three different databases. Further analysis could explore the potential significance of differences between databases and the biases within each.\n",
    "\n",
    "I've decided to clean these 3 variables first as they appear to have high correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe of absolute correlations between features excluding autocorrelation combinations\n",
    "corr_pairs = corr_matrix.stack().abs().reset_index()\n",
    "corr_pairs.columns = ['variable_1', 'variable_2', 'abs_correlation']\n",
    "corr_pairs = corr_pairs[corr_pairs['variable_1'] != corr_pairs['variable_2']]\n",
    "corr_pairs = corr_pairs.sort_values(by='abs_correlation', ascending=False)\n",
    "\n",
    "# display the new dataframe\n",
    "print(corr_pairs.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above displays all correlations in descending order. This means that the variables at the top of the chart have higher correlations than those at the bottom of the chart. We also see that the three allele columns we were talking about earlier appear near the top. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new correlation matrix from the filtered pairs\n",
    "corr_matrix_filtered = pd.pivot_table(corr_pairs, values='abs_correlation', index='variable_1', columns='variable_2')\n",
    "\n",
    "# create a heatmap of the filtered correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix_filtered, cmap='coolwarm', annot=True, fmt='.2f')\n",
    "plt.title('Filtered Correlation Matrix Heatmap (High)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason correlations were calculated is because variables with high correlations often produce: \n",
    "\n",
    "1. Redundant features\n",
    "2. Multicollinearity\n",
    "3. Decreased model performance\n",
    "\n",
    "Generally, high correlations are a warning sign. If distributions prove to be similar statistically, only using one of the 2 variables in a pair of high correlation would be beneficial. Let's visualize our distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create three subplots for the histograms\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(10, 4))\n",
    "\n",
    "# Plot histograms for each column\n",
    "\n",
    "ax1.hist(df['AF_ESP'], bins=10, density=True)\n",
    "ax1.set_title('AF_ESP Distribution')\n",
    "\n",
    "\n",
    "ax2.hist(df['AF_EXAC'], bins=10, density=True)\n",
    "ax2.set_title('AF_EXAC Distribution')\n",
    "\n",
    "\n",
    "ax3.hist(df['AF_TGP'], bins=10, density=True)\n",
    "ax3.set_title('AF_TGP Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributions of Allele frequency above appear to look similar. Combining that with the 0% missing values and high correlation for all three enhance the argument that the columns are not significiantly different.\n",
    "\n",
    "However...\n",
    "\n",
    "One key piece of information has yet to be dealt with. The columns look the same and have 0% missing values, but with regards to the original database, missing values in these columns are labeled as \"0\". Thus, python will count these values as non-null instead of null when iterating through the column. \n",
    "\n",
    "Let's further explore the actual missing values in the columns that are labeled as \"0\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allele_df = df[['AF_ESP', 'AF_EXAC', 'AF_TGP']]\n",
    "\n",
    "allele_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initiate count of three new variables\n",
    "\n",
    "esp_zeros = 0\n",
    "exac_zeros = 0\n",
    "tgp_zeros = 0\n",
    "\n",
    "# iterate through allele_df and print count of zeroes \n",
    "\n",
    "for column in allele_df.columns:\n",
    "    column_values = allele_df[column].values\n",
    "    zeros_count = len(column_values[column_values == 0])\n",
    "    \n",
    "    if column == 'AF_ESP':\n",
    "        esp_zeros += zeros_count\n",
    "    elif column == 'AF_EXAC':\n",
    "        exac_zeros += zeros_count\n",
    "    elif column == 'AF_TGP':\n",
    "        tgp_zeros += zeros_count\n",
    "\n",
    "print(\"Count of zeroes (missing values) in AF_ESP column:\", esp_zeros)\n",
    "print(\"Count of zeroes (missing values) in AF_EXAC column:\", exac_zeros)\n",
    "print(\"Count of zeroes (missing values) in AF_TGP column:\", tgp_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esp_missing = round((esp_zeros / len(allele_df)) * 100, 2)\n",
    "exac_missing = round((exac_zeros / len(allele_df)) * 100, 2)\n",
    "tgp_missing = round((tgp_zeros / len(allele_df)) * 100, 2)\n",
    "\n",
    "print(\"Percentage of actual missing values in AF_ESP column:\", esp_missing)\n",
    "print(\"Percentage of actual missing values in AF_EXAC column:\", exac_missing)\n",
    "print(\"Percentage of actual missing values in AF_TGP column:\", tgp_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All three columns appear to have different counts of zero. Thus, they have different counts of actual null values. \n",
    "\n",
    "ESP and TGP have similar missing percentages at 54.89 and 58.25, respectively. EXAC, however, has only 36.89 % missing. This seems to be much less, so it's possible the EXAC column is more comprehensive with respect to allele frequency data collection. As a scientist though, it's important to remember that just because something appears to be different doesn't mean it's significant. Hence, association is not synonymous with causation. \n",
    "\n",
    "The next step is to visualize the distributions after removing null-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allele_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in allele_df.columns:\n",
    "    allele_df.loc[allele_df[column] == 0, column] = None\n",
    "\n",
    "allele_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'allele_df' dataframe above now has the correct count of non-null values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distributions and print the count of column values\n",
    "for column in allele_df.columns:\n",
    "    column_values = allele_df[column].dropna()\n",
    "\n",
    "    # Plot the distribution\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(column_values, bins=20)\n",
    "    plt.title(column)\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "    # Print the count of column values\n",
    "    print(\"Column:\", column)\n",
    "    print(\"Count:\", len(column_values))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributions of the allele frequency columns are displayed above. Similar to the distributions before dropping nulls, the distribution after dropping nulls show heavy right skew for all three distributions. The next step in EDA is to utilize different techniques to fill the new filtered dataframe null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the original DataFrame\n",
    "allele_df_filled = allele_df.copy()\n",
    "\n",
    "# Fill null values using different methods\n",
    "allele_df_filled['AF_ESP_mean'] = allele_df['AF_ESP'].fillna(allele_df['AF_ESP'].mean())\n",
    "allele_df_filled['AF_ESP_median'] = allele_df['AF_ESP'].fillna(allele_df['AF_ESP'].median())\n",
    "allele_df_filled['AF_ESP_interpolate'] = allele_df['AF_ESP'].interpolate()\n",
    "\n",
    "# Perform Anderson-Darling test for each filled column\n",
    "columns_to_test = ['AF_ESP_mean', 'AF_ESP_median', 'AF_ESP_interpolate']\n",
    "\n",
    "for column in columns_to_test:\n",
    "    result = stats.anderson(allele_df_filled[column].dropna())\n",
    "    print(\"Anderson-Darling test for\", column)\n",
    "    print(\"Statistic: %.3f\" % result.statistic)\n",
    "    print(\"Critical Values: \", result.critical_values)\n",
    "    print(\"Significance Levels: \", result.significance_level)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate skewness for each filled column\n",
    "skewness = {\n",
    "    'AF_ESP_mean': allele_df_filled['AF_ESP_mean'].skew(),\n",
    "    'AF_ESP_median': allele_df_filled['AF_ESP_median'].skew(),\n",
    "    'AF_ESP_interpolate': allele_df_filled['AF_ESP_interpolate'].skew()\n",
    "}\n",
    "\n",
    "# Print the skewness for each filled column\n",
    "for column, skew in skewness.items():\n",
    "    print(\"Skewness for\", column, \":\", skew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate kurtosis for each filled column\n",
    "kurtosis = {\n",
    "    'AF_ESP_mean': allele_df_filled['AF_ESP_mean'].kurtosis(),\n",
    "    'AF_ESP_median': allele_df_filled['AF_ESP_median'].kurtosis(),\n",
    "    'AF_ESP_interpolate': allele_df_filled['AF_ESP_interpolate'].kurtosis()\n",
    "}\n",
    "\n",
    "# Print the kurtosis for each filled column\n",
    "for column, kurt in kurtosis.items():\n",
    "    print(\"Kurtosis for\", column, \":\", kurt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three methods were used to fill in null values:\n",
    "\n",
    "1. Mean\n",
    "2. Median\n",
    "3. Interpolation = winner!\n",
    "\n",
    "Of the three, interpolation produced the smallest skew and kurtosis. This could indicate that the data is a bit more normally distributed after undergoing interpolation than filling with mean or median.\n",
    "\n",
    "Thus, we will continue with using interpolation for these columns for the remainder of our cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the original DataFrame\n",
    "allele_final = allele_df.copy()\n",
    "\n",
    "# Fill null values using interpolation\n",
    "allele_final['ESP_interpolate'] = allele_df['AF_ESP'].interpolate()\n",
    "allele_final['EXAC_interpolate'] = allele_df['AF_EXAC'].interpolate()\n",
    "allele_final['TGP_interpolate'] = allele_df['AF_TGP'].interpolate()\n",
    "\n",
    "allele_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allele_final.drop(['AF_ESP', 'AF_EXAC', 'AF_TGP'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allele_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null values in each column have successfully been interpolated. After doing this, we need to assess the effects of different transformations in order to increase normality of the distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "winsorized_df = allele_final.apply(winsorize, limits=[0.05, 0.05])\n",
    "\n",
    "# Log transformation\n",
    "log_transformed_df = np.log(winsorized_df)\n",
    "\n",
    "# Square root transformation\n",
    "sqrt_transformed_df = np.sqrt(winsorized_df)\n",
    "\n",
    "# Compare distributions with histograms\n",
    "for column in winsorized_df.columns:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Original winsorized data\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.hist(winsorized_df[column], bins=20)\n",
    "    plt.title(column + \" Winsorized\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "    # Log transformed data\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.hist(log_transformed_df[column], bins=20)\n",
    "    plt.title(column + \" Log Transformed\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "    # Square root transformed data\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.hist(sqrt_transformed_df[column], bins=20)\n",
    "    plt.title(column + \" Square Root Transformed\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Compare distributions with boxplots\n",
    "transformed_dfs = [winsorized_df, log_transformed_df, sqrt_transformed_df]\n",
    "transformation_labels = ['Winsorized', 'Log Transformed', 'Square Root Transformed']\n",
    "\n",
    "for i, transformed_df in enumerate(transformed_dfs):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.boxplot(transformed_df.values)\n",
    "    plt.xticks(np.arange(1, len(winsorized_df.columns) + 1), winsorized_df.columns, rotation=45)\n",
    "    plt.title(transformation_labels[i] + \" Boxplot\")\n",
    "    plt.xlabel(\"Column\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histograms and boxplots above visually show that log transformation is the most successful technique for all three allele columns. Thus, we will continue with log transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "# Perform Shapiro-Wilk test on each log-transformed column\n",
    "for column in log_transformed_df.columns:\n",
    "    _, p_value = shapiro(log_transformed_df[column])\n",
    "    print(\"Shapiro-Wilk test for\", column)\n",
    "    print(\"p-value:\", p_value)\n",
    "    if p_value > 0.05:\n",
    "        print(\"The data is likely normally distributed.\\n\")\n",
    "    else:\n",
    "        print(\"The data is likely not normally distributed.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Q-Q plots for each log-transformed column\n",
    "for column in log_transformed_df.columns:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    stats.probplot(log_transformed_df[column], dist='norm', plot=plt) \n",
    "    plt.title(\"Q-Q Plot for \" + column)\n",
    "    plt.xlabel(\"Theoretical Quantiles\")\n",
    "    plt.ylabel(\"Sample Quantiles\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "column1 = log_transformed_df['ESP_interpolate']\n",
    "column2 = log_transformed_df['EXAC_interpolate']\n",
    "column3 = log_transformed_df['TGP_interpolate']\n",
    "\n",
    "# Perform the Kruskal-Wallis test\n",
    "statistic, p_value = kruskal(column1, column2, column3)\n",
    "\n",
    "print(\"Kruskal-Wallis test statistic:\", statistic)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "for column in log_transformed_df.columns:\n",
    "    statistic, p_value = wilcoxon(log_transformed_df[column])\n",
    "    print(\"Wilcoxon signed-rank test for\", column)\n",
    "    print(\"Test statistic:\", statistic)\n",
    "    print(\"p-value:\", p_value)\n",
    "    if p_value > 0.05:\n",
    "        print(\"There is no significant difference between the paired samples.\\n\")\n",
    "    else:\n",
    "        print(\"There is a significant difference between the paired samples.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the three allele frequency columns are still proving to be not normally distributed and remain statistically different. However, the distribution has been improved via interpolation and log transformation. Additonal nonparametric tests in the future may be beneficial when building the model. More data on the significance will be analyzed in the future when the model is implemented with different combinations of the allele frequency columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allele_final = log_transformed_df.copy()\n",
    "\n",
    "allele_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allele_final['MEAN_AF'] = allele_final[['ESP_interpolate', 'EXAC_interpolate', 'TGP_interpolate']].mean(axis=1)\n",
    "\n",
    "allele_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've decided to engineer a 'MEAN_AF' column in the allele dataframe that calculates the mean of all three allele columns. This is primarily for experimentation. I may end up dropping it from the model in the future due to the issue of non-normality. Let's now insert our new allele columns in the main 'df' dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the interpolated columns from 'allele_final' to 'df'\n",
    "df = df.join(allele_final[['ESP_interpolate', 'EXAC_interpolate', 'TGP_interpolate']])\n",
    "\n",
    "# Drop the old columns\n",
    "df.drop(['AF_ESP', 'AF_EXAC', 'AF_TGP'], axis=1, inplace=True)\n",
    "\n",
    "# Rename the interpolated columns \n",
    "df.rename(columns={'ESP_interpolate': 'New_ESP', 'EXAC_interpolate': 'New_EXAC', 'TGP_interpolate': 'New_TGP'}, inplace=True)\n",
    "\n",
    "# Add the 'MEAN_AF' column from 'allele_final' to 'df'\n",
    "df['New_MEAN_AF'] = allele_final['MEAN_AF']\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the allele columns are cleaned, we must separate the numeric and non-numeric columns again. This is because numbers and objects are treated differently when analyzing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = df.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "numeric_columns.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = numeric_columns.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, cmap='coolwarm', annot=True, fmt='.2f')\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation heat map is improving. Interestingly, the high correlations amongst the transformed allele columns have been reduced after the introduction of the 'New_MEAN_AF' column. While the ratios are still high, it's good to note a reduction. I can't drop any of them yet though due to a recurring issue of non-normality.\n",
    "\n",
    "The map shows a couple more points of high correlation outside of the disculled allele frequencies. Specifically, there is high correlation between CADD_RAW and CADD_PHRED (0.96). This makes sense in the context of genetic pathogenicity. \n",
    "\n",
    "CADD = Combined Annotation Dependent Depletion\n",
    "\n",
    "CADD Raw = continuous score that measures deleteriousness of a genetic variant, can be positive or negative.\n",
    "\n",
    "CADD Phred = a normalized and transformed version of CADD Raw, Phred-like scale, logarithmically scaled and rounded, ranges from 1-99.\n",
    "\n",
    "For this project, CADD_Phred will be used for 3 reasons:\n",
    "\n",
    "1. Standardized Scale = ranges from 1-99, sets appropriate thresholds\n",
    "2. Population Comparison = Phred-like scale makes it easier to compare\n",
    "3. Large Sample Size = handles a large sample size of over 60,000 better than CADD Raw by providing a discrete scale.\n",
    "\n",
    "Thus, CADD Raw will be dropped from the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('CADD_RAW', axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = df.select_dtypes(include=['int64', 'float64'])\n",
    "corr_matrix = numerical_columns.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, cmap='coolwarm', annot=True, fmt='.2f')\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical columns are improving. However, the column 'BLOSUM62' has a high percentage of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['BLOSUM62'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BLOSUM62'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_stats = df['BLOSUM62'].describe()\n",
    "print(summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing values from the column\n",
    "column_without_missing = df['BLOSUM62'].dropna()\n",
    "\n",
    "# Perform Shapiro-Wilk test\n",
    "shapiro_statistic, shapiro_p_value = shapiro(column_without_missing)\n",
    "print(\"Shapiro-Wilk Test - Statistic:\", shapiro_statistic)\n",
    "print(\"Shapiro-Wilk Test - p-value:\", shapiro_p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BLOSUM62 column statistically proves to be non-normally distributed. I've decided to drop this column for this reason along with the high null percentage of 60%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('BLOSUM62', axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = df.select_dtypes(include=['int64', 'float64'])\n",
    "corr_matrix = numerical_columns.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, cmap='coolwarm', annot=True, fmt='.2f')\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of rows and columns for the subplots\n",
    "num_cols = len(numerical_columns.columns)\n",
    "num_rows = (num_cols + 1) // 2\n",
    "\n",
    "# Create the subplots\n",
    "fig, axes = plt.subplots(num_rows, 2, figsize=(12, num_rows*5))\n",
    "\n",
    "# Iterate through each column\n",
    "for i, column in enumerate(numerical_columns.columns):\n",
    "    # Calculate the subplot position\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    \n",
    "    # Plot histogram for the current column\n",
    "    axes[row, col].hist(numerical_columns[column].dropna(), bins=10)\n",
    "    axes[row, col].set_title(f\"Histogram of {column}\")\n",
    "    axes[row, col].set_xlabel(\"Value\")\n",
    "    axes[row, col].set_ylabel(\"Frequency\")\n",
    "\n",
    "    # Print unique value counts\n",
    "    unique_vals = numerical_columns[column].nunique()\n",
    "    axes[row, col].text(0.75, 0.9, f\"Unique: {unique_vals}\", transform=axes[row, col].transAxes)\n",
    "\n",
    "# Hide unused subplots if the number of columns is odd\n",
    "if num_cols % 2 != 0:\n",
    "    axes[-1, -1].axis(\"off\")\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the plots generated above, 'CLASS' and 'STRAND' appear to be binary with only two unique values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leftover_numeric = df[['STRAND', 'LoFtool', 'CADD_PHRED']]\n",
    "\n",
    "leftover_numeric.info()\n",
    "\n",
    "df['STRAND'].fillna(df['STRAND'].mode().iloc[0], inplace=True)\n",
    "\n",
    "leftover_numeric = leftover_numeric.fillna(leftover_numeric.mean())\n",
    "leftover_numeric.info()\n",
    "\n",
    "\n",
    "# Generate histograms\n",
    "leftover_numeric.hist(figsize=(10, 6))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Generate boxplots\n",
    "leftover_numeric.boxplot(figsize=(10, 6))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leftover_numeric_log = leftover_numeric.copy()\n",
    "\n",
    "# Replace invalid values with NaN\n",
    "leftover_numeric_log['CADD_PHRED'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "# Apply logarithm after replacing invalid values\n",
    "leftover_numeric_log['LoFtool'] = np.log(leftover_numeric['LoFtool'])\n",
    "leftover_numeric_log['CADD_PHRED'] = np.log(leftover_numeric_log['CADD_PHRED'])\n",
    "leftover_numeric_log['STRAND'] = df['STRAND']\n",
    "\n",
    "# Generate histograms\n",
    "leftover_numeric_log.hist(figsize=(10, 6))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Generate boxplots\n",
    "leftover_numeric_log.boxplot(figsize=(10, 6))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Perform Shapiro-Wilk test on 'leftover_numeric'\n",
    "statistic, p_value = shapiro(leftover_numeric['STRAND'])\n",
    "\n",
    "print(\"Shapiro-Wilk Test:\")\n",
    "print(\"Test Statistic:\", statistic)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mstats\n",
    "\n",
    "# Apply winsorization column-wise\n",
    "leftover_numeric_winsorized = leftover_numeric.apply(lambda x: mstats.winsorize(x, limits=[0.05, 0.05]))\n",
    "\n",
    "# Generate histograms after winsorization\n",
    "leftover_numeric_winsorized.hist(figsize=(10, 6))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Generate boxplots after winsorization\n",
    "leftover_numeric_winsorized.boxplot(figsize=(10, 6))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, winsorization appears to have removed all of the outliers. However, the histograms look more normal after log transformation. The only problem with log transformation is there are several outliers in the 'CADD_PHRED' column boxplot after transformation. \n",
    "\n",
    "Let's add a constant to the log transformation of 'CADD_PHRED' to counteract the remaining outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "leftover_numeric_log = leftover_numeric.copy()\n",
    "\n",
    "leftover_numeric_log['STRAND'] = leftover_numeric['STRAND']\n",
    "leftover_numeric_log['LoFtool'] = np.log(leftover_numeric['LoFtool'])\n",
    "leftover_numeric_log['CADD_PHRED'] = np.log(leftover_numeric['CADD_PHRED'] + 2)  # Adding a constant before taking the log\n",
    "\n",
    "# Generate histograms\n",
    "leftover_numeric_log.hist(figsize=(10, 6))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Generate boxplots\n",
    "leftover_numeric_log.boxplot(figsize=(10, 6))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "statistic, p_value = shapiro(leftover_numeric)\n",
    "\n",
    "print(\"Shapiro-Wilk Test:\")\n",
    "print(\"Test Statistic:\", statistic)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# Perform Kolmogorov-Smirnov test between original data and log-transformed data\n",
    "statistic_log, p_value_log = ks_2samp(leftover_numeric.values.flatten(), leftover_numeric_log.values.flatten())\n",
    "\n",
    "# Perform Kolmogorov-Smirnov test between original data and winsorized data\n",
    "statistic_winsorized, p_value_winsorized = ks_2samp(leftover_numeric.values.flatten(), leftover_numeric_winsorized.values.flatten())\n",
    "\n",
    "print(\"Kolmogorov-Smirnov Test - Log Transformation:\")\n",
    "print(\"Test Statistic:\", statistic_log)\n",
    "print(\"p-value:\", p_value_log)\n",
    "\n",
    "print(\"Kolmogorov-Smirnov Test - Winsorization:\")\n",
    "print(\"Test Statistic:\", statistic_winsorized)\n",
    "print(\"p-value:\", p_value_winsorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the columns appear to be more normally distributed and log transformation takes the win."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.update(leftover_numeric_log)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "numeric_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numeric columns in the dataframe have now been cleaned and transformed. Let's now shift our focus to the variables labeled as objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cols = df.select_dtypes(include=['object'])\n",
    "object_cols.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our new dataframe with isolated object columns, we can begin examining null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe of missing percentages and visualize\n",
    "\n",
    "missing_percentage_df = pd.DataFrame(columns=['Column', 'Missing Percentage'])\n",
    "\n",
    "for column in object_cols.columns:\n",
    "    missing_percentage = (object_cols[column].isnull().sum() / len(object_cols)) * 100\n",
    "    missing_percentage_df = pd.concat([missing_percentage_df, pd.DataFrame({'Column': [column], 'Missing Percentage': [missing_percentage]})], ignore_index=True)\n",
    "\n",
    "# descending order \n",
    "\n",
    "missing_percentage_df = missing_percentage_df.sort_values('Missing Percentage', ascending=False)\n",
    "print(missing_percentage_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cols.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate objects whose values appear to be abnormal\n",
    "\n",
    "weird_objects = object_cols[['CHROM', 'cDNA_position', \n",
    "                             'CDS_position', 'Protein_position']]\n",
    "\n",
    "weird_objects.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The four columns above were chosen because each column is theoretically supposed to contain numeric values, but python has classified them as objects due to data issues. Specifically, there appears to be '-' (hyphens) in a small percentage of cells. I've decided to strip the '-' and all values after it in each cell due to my currently limited data cleaning skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through each column and perform string manipulation\n",
    "for column in weird_objects.columns:\n",
    "    if weird_objects[column].apply(lambda x: isinstance(x, str)).all():\n",
    "        weird_objects.loc[:, column] = weird_objects[column].str.split('-').str[0].copy()\n",
    "        \n",
    "\n",
    "# convert to numeric to finish\n",
    "weird_objects = weird_objects.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "weird_objects.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns have now been converted to floats. It's time to send these new columns down our data cleaning pipeline. This includes analyzing nulls, outliers, and distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in weird_objects.columns:\n",
    "    null_count = weird_objects[col].isnull().sum()\n",
    "    total_rows = len(weird_objects)\n",
    "    missing_percentage = (null_count / total_rows) * 100\n",
    "    \n",
    "    print(f\"Column '{col}' has a missing percentage of {missing_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the median of each column\n",
    "column_medians = weird_objects.median()\n",
    "\n",
    "# Fill null values with column medians\n",
    "weird_objects_filled = weird_objects.fillna(column_medians)\n",
    "\n",
    "# Plot histograms of filled data\n",
    "weird_objects_filled.hist(bins=10, figsize=(12, 8))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot boxplots of filled data\n",
    "weird_objects_filled.boxplot(figsize=(12, 8))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox\n",
    "\n",
    "# Log transform the data\n",
    "weird_objects_log = np.log1p(weird_objects_filled)\n",
    "\n",
    "# Plot histograms of log-transformed data\n",
    "weird_objects_log.hist(bins=10, figsize=(12, 8))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot boxplots of log-transformed data\n",
    "weird_objects_log.boxplot(figsize=(12, 8))\n",
    "plt.title(\"Log transformation\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Apply Box-Cox transformation to each column\n",
    "weird_objects_boxcox = pd.DataFrame()\n",
    "shift = 1e-6  # Small positive constant\n",
    "\n",
    "for col in weird_objects_filled.columns:\n",
    "    if np.all(weird_objects_filled[col] > 0):\n",
    "        transformed_data, _ = boxcox(weird_objects_filled[col])\n",
    "        weird_objects_boxcox[col] = transformed_data\n",
    "    else:\n",
    "        shifted_data = weird_objects_filled[col] + shift\n",
    "        transformed_data, _ = boxcox(shifted_data)\n",
    "        weird_objects_boxcox[col] = transformed_data\n",
    "\n",
    "# Plot histograms of square root transformed data\n",
    "weird_objects_sqrt = np.sqrt(weird_objects_filled)\n",
    "weird_objects_sqrt.hist(bins=10, figsize=(12, 8))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot boxplots of square root transformed data\n",
    "weird_objects_sqrt.boxplot(figsize=(12, 8))\n",
    "plt.title(\"Square root transformation\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot histograms of Box-Cox transformed data\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, column in enumerate(weird_objects_boxcox.columns):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.hist(weird_objects_boxcox[column], bins=10)\n",
    "    plt.title(f'Column: {column}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot boxplots of Box-Cox transformed data\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.boxplot(weird_objects_boxcox.values, labels=weird_objects_boxcox.columns)\n",
    "plt.title('Box-Cox transformation')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the three transformations attempted, Box-Cox and log transformations work best on the data. Let's generate some QQ plots to identify which one of the two is best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import probplot\n",
    "\n",
    "# Create QQ plot for log-transformed data\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, col in enumerate(weird_objects_log.columns):\n",
    "    plt.subplot(2, len(weird_objects_log.columns)//2, i+1)\n",
    "    probplot(weird_objects_log[col], plot=plt)\n",
    "    plt.title(f'Log-transformed - {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create QQ plot for Box-Cox transformed data\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, col in enumerate(weird_objects_boxcox.columns):\n",
    "    plt.subplot(2, len(weird_objects_boxcox.columns)//2, i+1)\n",
    "    probplot(weird_objects_boxcox[col], plot=plt)\n",
    "    plt.title(f'Box-Cox transformed - {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Q-Q plots above indicate that Box-Cox transformation outperforms log transformation by a small fraction. Thus, Box-Cox transformation will be used with this specific data.\n",
    "\n",
    "Let's now re-insert the updated and cleaned columns into the main dataframe and then visualize our new 'numerical' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.update(weird_objects_boxcox)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric = df.select_dtypes(include=[object])\n",
    "non_numeric.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further reduce complexity of our future model, there are a few more object columns that can be dropped.\n",
    "\n",
    "1. BAM_EDIT = Binary Map Alignment, indicates whether it's stored in a particular database, not relevant.\n",
    "2. INTRON = severely low amount of non-null values\n",
    "3. EXON = contains dates, not performing time series, not relevant\n",
    "4. CLNDISB = Provides MedGen database identifiers, not relevant\n",
    "5. CLNHGVS = provides database identifier, not relevant\n",
    "6. MC = repeat of Consequence with additional database identifier\n",
    "7. CLNVI = lab location identifier, not relevant for current project.\n",
    "8. SYMBOL = another identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['BAM_EDIT', 'INTRON', 'EXON', 'CLNDISDB', 'CLNHGVS', 'MC', 'CLNVI', 'SYMBOL'], axis=1, inplace=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric = df.select_dtypes(include=[object])\n",
    "non_numeric.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_counts = non_numeric.nunique()\n",
    "\n",
    "# Sort the columns based on the number of unique variables\n",
    "sorted_columns = unique_counts.sort_values()\n",
    "\n",
    "# Print the sorted columns and their corresponding unique counts\n",
    "print(\"Unique counts:\\n\")\n",
    "for column in sorted_columns.index:\n",
    "    unique_count = sorted_columns[column]\n",
    "    print(f\"{column}: {unique_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're starting to understand our object variables a bit better now. There's a few things I notice:\n",
    "\n",
    "1. 'Allele' should only have 4 values (AGTC) in terms of genetic knowledge.\n",
    "2. ALT and REF should also only have 4 values (AGTC) in terms of genetic knowledge.\n",
    "\n",
    "Let's clean those columns so that there are only 4 unique values for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame\n",
    "columns_to_clean = ['Allele', 'REF', 'ALT']\n",
    "\n",
    "for column in columns_to_clean:\n",
    "    for i, value in enumerate(df[column]):\n",
    "        if value not in ['A', 'G', 'T', 'C']:\n",
    "            df.at[i, column] = None  # Replace with None for null\n",
    "\n",
    "for column in columns_to_clean:\n",
    "    unique_values = df[column].unique()\n",
    "    unique_count = df[column].nunique()\n",
    "    print(f\"Column: {column}\")\n",
    "    print(f\"Unique Values: {unique_values}\")\n",
    "    print(f\"Unique Value Count: {unique_count}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_plot = ['Allele', 'REF', 'ALT']\n",
    "\n",
    "# iterate and plot histograms of isolated columns\n",
    "for column in columns_to_plot:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    df[column].value_counts().plot(kind='bar')\n",
    "    plt.title(f'Histogram of {column}')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are very few missing values in all 3 columns. Thus, I've chosen to imput the missing values with the mode of the respective variables since they are categorical variables with only 4 unique values each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_impute = ['REF', 'ALT', 'Allele']\n",
    "\n",
    "for column in columns_to_impute:\n",
    "    df[column].fillna(df[column].mode().iloc[0], inplace=True)\n",
    "    \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unique values of object columns that appeared earlier show that various features are very clearly categorical. Such categorical variables are:\n",
    "\n",
    "1. REF (Reference allele): The original allele of a gene, commonly found in the population.\n",
    "2. ALT (Altered allele): The mutated allele of a gene, representing an alternative form of the genetic sequence compared to the reference allele.\n",
    "3. CLNVC (Clinical variant class): Describes the type or category of a genetic variant based on its clinical significance or functional impact.\n",
    "4. IMPACT: Indicates the functional consequence of a genetic variant on the gene or protein product.\n",
    "5. SIFT: Predicts the potential impact of amino acid substitutions caused by genetic variants on protein function based on sequence conservation and other factors.\n",
    "6. PolyPhen: Predicts the possible functional consequences of amino acid substitutions caused by genetic variants on protein structure and function.\n",
    "7. Consequence: Resulting DNA mutation (such as missense a mutation).\n",
    "\n",
    "However, we have encountered more redundancy with respect to genetic domain knowledge. Feature_type, BIOTYPE, and Feature all only have 2 values that are already included in the Consequence column. They don't add any additional information to the model. Thus, they can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Feature', 'Feature_type', 'BIOTYPE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_object = df.select_dtypes(include='object')\n",
    "\n",
    "print(\"Unique Counts:\\n\")\n",
    "    \n",
    "for column in df_object.columns:\n",
    "    unique_values = df_object[column].nunique()\n",
    "    print(f\"{column}: {unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_object.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate the remaining object columns that have missing values\n",
    "leftover_object = df[['REF', 'Amino_acids', 'Codons', 'SIFT', 'PolyPhen']]\n",
    "\n",
    "print(\"Unique Counts:\\n\")\n",
    "    \n",
    "for column in leftover_object.columns:\n",
    "    unique_values = leftover_object[column].nunique()\n",
    "    print(f\"{column}: {unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift_counts = df['SIFT'].value_counts(dropna=False)\n",
    "print(sift_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_counts = df['PolyPhen'].value_counts(dropna=False)\n",
    "print(poly_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIFT and PolyPhen are tools used in genetics to predict how changes in genes may affect proteins. SIFT looks at how similar the changed protein is to other proteins, while PolyPhen considers additional information like protein characteristics and structures to determine if the change is likely to be harmful or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "leftover_object['SIFT'].value_counts().plot(kind='bar')\n",
    "plt.xlabel('SIFT')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Frequency of SIFT')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Generate bar plot for 'PolyPhen'\n",
    "plt.figure(figsize=(10, 6))\n",
    "leftover_object['PolyPhen'].value_counts().plot(kind='bar')\n",
    "plt.xlabel('PolyPhen')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Frequency of PolyPhen')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.copy()\n",
    "df_test = df_test.dropna(subset=['PolyPhen'])\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe to include only the required columns\n",
    "subset_df = df_test[['Amino_acids', 'Codons']].copy()\n",
    "\n",
    "# Get the top N most frequent values in 'Amino_acids' column\n",
    "top_n_amino_acids = subset_df['Amino_acids'].value_counts().head(30)\n",
    "\n",
    "# Plot the top N most frequent values in 'Amino_acids' column\n",
    "top_n_amino_acids.plot(kind='bar')\n",
    "plt.title('Top 30 Amino Acids combos')\n",
    "plt.xlabel('Amino Acids')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Get the top N most frequent values in 'Codons' column\n",
    "top_n_codons = subset_df['Codons'].value_counts().head(30)\n",
    "\n",
    "# Plot the top N most frequent values in 'Codons' column\n",
    "top_n_codons.plot(kind='bar')\n",
    "plt.title('Top 30 Codons combos')\n",
    "plt.xlabel('Codons')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "correlation_matrix = df_test.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', square=True)\n",
    "\n",
    "# Set the title\n",
    "plt.title('Correlation Heatmap')\n",
    "\n",
    "# Display the heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the calculated values\n",
    "data_clean2 = {\n",
    "    'Column': [],\n",
    "    'Unique_Count': [],\n",
    "    'Data_Type': [],\n",
    "    'Numeric': [],\n",
    "    'Continuous': []\n",
    "}\n",
    "\n",
    "# Iterate through each column in 'df'\n",
    "for column in df_test.columns:\n",
    "    unique_count = df_test[column].nunique()\n",
    "    data_type = df_test[column].dtype\n",
    "\n",
    "    # Identify if column is numeric or non-numeric (categorical)\n",
    "    is_numeric = np.issubdtype(data_type, np.number)\n",
    "    is_continuous = is_numeric and unique_count > 50\n",
    "\n",
    "    # Add the calculated values to the dictionary\n",
    "    data_clean2['Column'].append(column)\n",
    "    data_clean2['Unique_Count'].append(unique_count)\n",
    "    data_clean2['Data_Type'].append(data_type)\n",
    "    data_clean2['Numeric'].append(is_numeric)\n",
    "    data_clean2['Continuous'].append(is_continuous)\n",
    "\n",
    "temp_data_clean = pd.DataFrame(data_clean2)\n",
    "\n",
    "print('CLEANED DATAFRAME:\\n')\n",
    "print(temp_data_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "correlation_matrix = df_test.corr()\n",
    "\n",
    "# Initialize a list to store correlation pairs\n",
    "correlation_pairs = []\n",
    "\n",
    "# Iterate over the columns and store correlation pairs\n",
    "for column1 in correlation_matrix.columns:\n",
    "    for column2 in correlation_matrix.columns:\n",
    "        if column1 != column2:\n",
    "            correlation = correlation_matrix.loc[column1, column2]\n",
    "            correlation_pairs.append((column1, column2, abs(correlation)))\n",
    "\n",
    "# Sort the correlation pairs based on absolute correlation values in descending order\n",
    "correlation_pairs_sorted = sorted(correlation_pairs, key=lambda x: x[2], reverse=False)\n",
    "\n",
    "# Print the sorted correlation pairs\n",
    "for pair in correlation_pairs_sorted:\n",
    "    column1, column2, correlation = pair\n",
    "    print(f\"Correlation between {column1} and {column2}: {correlation:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_objects = df_test.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a new dataframe to store the label encoded values\n",
    "test_encoded = test_objects.copy()\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Iterate over each column in the dataframe\n",
    "for column in test_encoded.columns:\n",
    "    # Check if the column's dtype is 'object'\n",
    "    if test_encoded[column].dtype == 'object':\n",
    "        # Apply label encoding to the column\n",
    "        test_encoded[column] = label_encoder.fit_transform(test_encoded[column])\n",
    "\n",
    "# Check the encoded dataframe\n",
    "print(test_encoded.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert encoded columns to numeric type\n",
    "test_encoded = test_encoded.astype('int64')\n",
    "\n",
    "# Reassign the converted columns to clean_objects\n",
    "test_objects[['CHROM', 'REF', 'ALT', 'CLNDN', 'CLNVC', 'Allele', 'Consequence',\n",
    "               'IMPACT', 'cDNA_position', 'CDS_position', 'Protein_position',\n",
    "               'Amino_acids', 'Codons', 'SIFT', 'PolyPhen']] = test_encoded\n",
    "\n",
    "# Check the updated dataframe\n",
    "test_objects.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reassign the converted columns to clean_objects\n",
    "df_test[['CHROM', 'REF', 'ALT', 'CLNDN', 'CLNVC', 'Allele', 'Consequence',\n",
    "               'IMPACT', 'cDNA_position', 'CDS_position', 'Protein_position',\n",
    "               'Amino_acids', 'Codons', 'SIFT', 'PolyPhen']] = test_objects\n",
    "\n",
    "# Check the updated dataframe\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df_test2 = df_test.copy()\n",
    "\n",
    "# Step 1: Split dataset into predictors (X) and target variable (y)\n",
    "X = df_test2.drop('PolyPhen', axis=1)\n",
    "y = df_test2['PolyPhen']\n",
    "\n",
    "# Step 2: Encode categorical variables if needed\n",
    "\n",
    "# Step 3: Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Create logistic regression model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Step 5: Fit the model to the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Make predictions on the testing data\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Step 7: Evaluate the performance of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "df_test3 = df_test.copy()\n",
    "\n",
    "X = df_test3.drop('PolyPhen', axis=1)\n",
    "y = df_test3['PolyPhen']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the feature matrix\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create and fit the Lasso regression model\n",
    "lasso = Lasso(alpha=0.001)  # Adjust the alpha parameter as needed\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the coefficients\n",
    "coefficients = lasso.coef_\n",
    "\n",
    "# Identify selected features with non-zero coefficients\n",
    "selected_features = X.columns[coefficients != 0]\n",
    "\n",
    "# Print the selected features\n",
    "print(\"Selected Features:\")\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use selected features for logistic regression\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "# Create and fit the logistic regression model\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train_selected, y_train)\n",
    "\n",
    "# Predict the target variable for the test set\n",
    "y_pred = logreg.predict(X_test_selected)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[selected_features], y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and fit the Random Forest classifier\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert unknown values in 'PolyPhen' to NaN\n",
    "leftover_object['PolyPhen'].replace('unknown', np.nan, inplace=True)\n",
    "\n",
    "leftover_object.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print unique counts of DataFrame columns\n",
    "unique_counts = leftover_object.nunique()\n",
    "print(unique_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'Amino_acids' and 'Codons' columns\n",
    "leftover_object.drop(['Amino_acids', 'Codons'], axis=1, inplace=True)\n",
    "\n",
    "print(leftover_object.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leftover_object.drop('REF', axis=1, inplace=True)\n",
    "\n",
    "# Print information about the updated DataFrame\n",
    "print(leftover_object.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the previous columns, I was able to impute null values in different ways. However, SIFT and PolyPhen have a significant amount of missing values, more than 50% in fact. For the time being, I'm going to change the null values to 'Unknown' because there may be significance behind these values being unknown instead of just null. Since I'm skeptical, I'd rather not change much yet. In the future, the rows may have to be dropped entirely. Let's come back to that later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leftover_object.fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leftover_object.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['SIFT', 'PolyPhen']] = leftover_object[['SIFT', 'PolyPhen']]\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the columns for which you want to plot the bar plots\n",
    "columns_to_plot = ['SIFT', 'PolyPhen']\n",
    "\n",
    "# Plot bar plots for each column\n",
    "for column in columns_to_plot:\n",
    "    df[column].value_counts().plot(kind='bar', color='skyblue')\n",
    "    plt.title(column)\n",
    "    plt.xlabel('Unique Values')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift_counts = df['Amino_acids'].nunique()\n",
    "polyphen_counts = df['Codons'].nunique()\n",
    "\n",
    "print(\"Unique counts of Amino_acids column:\")\n",
    "print(sift_counts)\n",
    "\n",
    "print(\"\\nUnique counts of Codons column:\")\n",
    "print(polyphen_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last two columns to clean are the 'Amino_acids' and 'Codons' column. They both have a significant amount of unique values. Let's visualize some of the top values and their uniqueness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe to include only the required columns\n",
    "subset_df = df[['Amino_acids', 'Codons']].copy()\n",
    "\n",
    "# Get the top N most frequent values in 'Amino_acids' column\n",
    "top_n_amino_acids = subset_df['Amino_acids'].value_counts().head(30)\n",
    "\n",
    "# Plot the top N most frequent values in 'Amino_acids' column\n",
    "top_n_amino_acids.plot(kind='bar')\n",
    "plt.title('Top 20 Amino Acids')\n",
    "plt.xlabel('Amino Acids')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Get the top N most frequent values in 'Codons' column\n",
    "top_n_codons = subset_df['Codons'].value_counts().head(30)\n",
    "\n",
    "# Plot the top N most frequent values in 'Codons' column\n",
    "top_n_codons.plot(kind='bar')\n",
    "plt.title('Top 20 Codons')\n",
    "plt.xlabel('Codons')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Amino_acids'].fillna('Unknown', inplace=True)\n",
    "df['Codons'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the calculated values\n",
    "data_clean = {\n",
    "    'Column': [],\n",
    "    'Unique_Count': [],\n",
    "    'Data_Type': [],\n",
    "    'Numeric': [],\n",
    "    'Continuous': []\n",
    "}\n",
    "\n",
    "# Iterate through each column in 'df'\n",
    "for column in df_clean.columns:\n",
    "    unique_count = df_clean[column].nunique()\n",
    "    data_type = df_clean[column].dtype\n",
    "\n",
    "    # Identify if column is numeric or non-numeric (categorical)\n",
    "    is_numeric = np.issubdtype(data_type, np.number)\n",
    "    is_continuous = is_numeric and unique_count > 50\n",
    "\n",
    "    # Add the calculated values to the dictionary\n",
    "    data_clean['Column'].append(column)\n",
    "    data_clean['Unique_Count'].append(unique_count)\n",
    "    data_clean['Data_Type'].append(data_type)\n",
    "    data_clean['Numeric'].append(is_numeric)\n",
    "    data_clean['Continuous'].append(is_continuous)\n",
    "\n",
    "temp_data_clean = pd.DataFrame(data_clean)\n",
    "\n",
    "print('CLEANED DATAFRAME:\\n')\n",
    "print(temp_data_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blocks of code above display two different dataframes - the main 'df_clean' dataframe and the 'temp_data_clean' dataframe, which is simply a sub-dataframe engineered from 'df_clean' with specific calculations and cleaned columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move on to feature engineering to prepare for our model generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "correlation_matrix = df_clean.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', square=True)\n",
    "\n",
    "# Set the title\n",
    "plt.title('Correlation Heatmap')\n",
    "\n",
    "# Display the heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "correlation_matrix = df_clean.corr()\n",
    "\n",
    "# Initialize a list to store correlation pairs\n",
    "correlation_pairs = []\n",
    "\n",
    "# Iterate over the columns and store correlation pairs\n",
    "for column1 in correlation_matrix.columns:\n",
    "    for column2 in correlation_matrix.columns:\n",
    "        if column1 != column2:\n",
    "            correlation = correlation_matrix.loc[column1, column2]\n",
    "            correlation_pairs.append((column1, column2, abs(correlation)))\n",
    "\n",
    "# Sort the correlation pairs based on absolute correlation values in descending order\n",
    "correlation_pairs_sorted = sorted(correlation_pairs, key=lambda x: x[2], reverse=False)\n",
    "\n",
    "# Print the sorted correlation pairs\n",
    "for pair in correlation_pairs_sorted:\n",
    "    column1, column2, correlation = pair\n",
    "    print(f\"Correlation between {column1} and {column2}: {correlation:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the heat map and correlation analysis, certain variables are more favorable to be targets. Some variables like the allele frequency columns have high correlations with other variables and themselves. Thus, they are less suited to be targets and will be better served as predictors. \n",
    "\n",
    "There's one thing to keep in mind though - the correlations are only being calculated for the numerical values in the cleaned dataframe (df_clean). Thus, we must transform the 'object' columns to numeric to evaluate ALL variables of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_objects = df_clean.select_dtypes(include=['object'])\n",
    "clean_objects.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a new dataframe to store the label encoded values\n",
    "encoded_df = clean_objects.copy()\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Iterate over each column in the dataframe\n",
    "for column in encoded_df.columns:\n",
    "    # Check if the column's dtype is 'object'\n",
    "    if encoded_df[column].dtype == 'object':\n",
    "        # Apply label encoding to the column\n",
    "        encoded_df[column] = label_encoder.fit_transform(encoded_df[column])\n",
    "\n",
    "# Check the encoded dataframe\n",
    "print(encoded_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert encoded columns to numeric type\n",
    "encoded_df = encoded_df.astype('int64')\n",
    "\n",
    "# Reassign the converted columns to clean_objects\n",
    "clean_objects[['CHROM', 'REF', 'ALT', 'CLNDN', 'CLNVC', 'Allele', 'Consequence',\n",
    "               'IMPACT', 'cDNA_position', 'CDS_position', 'Protein_position',\n",
    "               'Amino_acids', 'Codons', 'SIFT', 'PolyPhen']] = encoded_df\n",
    "\n",
    "# Check the updated dataframe\n",
    "clean_objects.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns have successfully been converted to numeric. Now, we can replace the respective df_clean values with newly transformed object columns (now int64). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reassign the converted columns to clean_objects\n",
    "df_clean[['CHROM', 'REF', 'ALT', 'CLNDN', 'CLNVC', 'Allele', 'Consequence',\n",
    "               'IMPACT', 'cDNA_position', 'CDS_position', 'Protein_position',\n",
    "               'Amino_acids', 'Codons', 'SIFT', 'PolyPhen']] = clean_objects\n",
    "\n",
    "# Check the updated dataframe\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "correlation_matrix = df_clean.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', square=True)\n",
    "\n",
    "# Set the title\n",
    "plt.title('Correlation Heatmap')\n",
    "\n",
    "# Display the heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot going on in the correlation heat map above. However, there appear to be some heavy correlations between some variables. Let's print out all of the correlation pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store correlation pairs\n",
    "correlation_pairs = []\n",
    "\n",
    "# Iterate over the columns and store correlation pairs\n",
    "columns = correlation_matrix.columns\n",
    "num_columns = len(columns)\n",
    "\n",
    "for i in range(num_columns):\n",
    "    for j in range(i + 1, num_columns):\n",
    "        column1 = columns[i]\n",
    "        column2 = columns[j]\n",
    "        correlation = correlation_matrix.loc[column1, column2]\n",
    "        correlation_pairs.append((column1, column2, abs(correlation)))\n",
    "\n",
    "# Sort the correlation pairs based on absolute correlation values in descending order\n",
    "correlation_pairs_sorted = sorted(correlation_pairs, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "# Print the sorted correlation pairs\n",
    "for pair in correlation_pairs_sorted:\n",
    "    column1, column2, correlation = pair\n",
    "    print(f\"Correlation between {column1} and {column2}: {correlation:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df_clean.columns:\n",
    "    print(f'{column}: ', df_clean[column].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = df_clean.corr()['PolyPhen']\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_abs = df_clean.corr()['PolyPhen'].abs()\n",
    "corr_abs = corr_abs.sort_values(ascending=False)\n",
    "print(corr_abs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the code above, the 'PolyPhen' variables was chosen as the target variable. To recall, the 'PolyPhen' feature is a computational tool used in genetics to predict the potential impact of amino acid substitutions on protein structure and function, aiding in the assessment of genetic variant pathogenicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the columns for which you want to plot the bar plots\n",
    "columns_to_plot = ['PolyPhen']\n",
    "\n",
    "# Create subplots for each column\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot bar plot\n",
    "df[columns_to_plot[0]].value_counts().plot(kind='bar', ax=ax, color='skyblue')\n",
    "\n",
    "# Set title, x-label, and y-label\n",
    "ax.set_title(columns_to_plot[0])\n",
    "ax.set_xlabel('Unique Values')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "# Rotate x-axis labels\n",
    "ax.tick_params(axis='x', rotation=90)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df_clean2 = df_clean.copy()\n",
    "\n",
    "# Step 1: Split dataset into predictors (X) and target variable (y)\n",
    "X = df_clean2.drop('PolyPhen', axis=1)\n",
    "y = df_clean2['PolyPhen']\n",
    "\n",
    "# Step 2: Encode categorical variables if needed\n",
    "\n",
    "# Step 3: Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Create logistic regression model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Step 5: Fit the model to the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Make predictions on the testing data\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Step 7: Evaluate the performance of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "df_clean3 = df_clean.copy()\n",
    "\n",
    "X = df_clean3.drop('PolyPhen', axis=1)\n",
    "y = df_clean3['PolyPhen']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the feature matrix\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create and fit the Lasso regression model\n",
    "lasso = Lasso(alpha=0.1)  # Adjust the alpha parameter as needed\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the coefficients\n",
    "coefficients = lasso.coef_\n",
    "\n",
    "# Identify selected features with non-zero coefficients\n",
    "selected_features = X.columns[coefficients != 0]\n",
    "\n",
    "# Print the selected features\n",
    "print(\"Selected Features:\")\n",
    "print(selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use selected features for logistic regression\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "# Create and fit the logistic regression model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_selected, y_train)\n",
    "\n",
    "# Predict the target variable for the test set\n",
    "y_pred = logreg.predict(X_test_selected)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[selected_features], y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and fit the Random Forest classifier\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[selected_features], y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and fit the Naive Bayes classifier\n",
    "naive_bayes = GaussianNB()\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = naive_bayes.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Create polynomial features with interaction terms\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True)\n",
    "X_train_poly = poly.fit_transform(X_train_selected)\n",
    "X_test_poly = poly.transform(X_test_selected)\n",
    "\n",
    "# Create and fit the logistic regression model with polynomial features\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train_poly, y_train)\n",
    "\n",
    "# Predict the target variable for the test set\n",
    "y_pred = logreg.predict(X_test_poly)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy = DummyClassifier(strategy = 'most_frequent')\n",
    "dummy.fit(X_train, y_train)\n",
    "dummy.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Obtain the predictions from the logistic regression model with polynomial features\n",
    "y_pred_poly = logreg.predict(X_test_poly)\n",
    "\n",
    "# Create the confusion matrix\n",
    "confusion = confusion_matrix(y_test, y_pred_poly, labels=[1, 0])\n",
    "print(confusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm=confusion, target_names = ['Space', 'Not Space'], title = 'Confusion Matrix',normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print('Accuracy score: {:.2f}'.format(accuracy))\n",
    "print('Precision score: {:.2f}'.format(precision))\n",
    "print('Recall score: {:.2f}'.format(recall))\n",
    "print('F1 score: {:.2f}'.format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = logreg.predict_proba(X_test_poly)[:, 1]\n",
    "print(probs[1:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = [i for i, j in zip(probs, y_test) if j == 1]\n",
    "neg = [i for i, j in zip(probs, y_test) if j == 0]\n",
    "\n",
    "with plt.xkcd():\n",
    "  fig = plt.figure(figsize=(8, 4))\n",
    "\n",
    "  sns.distplot(pos, hist = False, kde = True, color='g',\n",
    "                 kde_kws = {'shade': True, 'linewidth': 3})\n",
    "\n",
    "  sns.distplot(neg, hist = False, kde = True, color='r',\n",
    "                 kde_kws = {'shade': True, 'linewidth': 3})\n",
    "\n",
    "  plt.plot([0.5, 0.5], [0, 25], '-b')\n",
    "  plt.annotate(\n",
    "        'The probability threshold\\npositive to the right\\nnegative to the left',\n",
    "        xy=(0.51, 15), arrowprops=dict(arrowstyle='->'), xytext=(0.6, 20))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the predicted probabilities with proper normalization\n",
    "probs = logreg.predict_proba(X_test_poly)\n",
    "probs_normalized = probs / probs.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Calculate the ROC-AUC score\n",
    "roc_auc = roc_auc_score(y_test, probs_normalized, multi_class='ovr')\n",
    "\n",
    "print('ROC-AUC score:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Binarize the labels\n",
    "y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n",
    "\n",
    "# Calculate the predicted probabilities for each class\n",
    "probs = logreg.predict_proba(X_test_poly)\n",
    "\n",
    "# Define the label names for each class\n",
    "class_labels = ['Unknown', 'Benign', 'Probably damaging', 'Possibly damaging']  # Adjust as needed\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "n_classes = y_test_bin.shape[1]\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], probs[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curve for each class with updated label names\n",
    "plt.figure()\n",
    "colors = ['blue', 'red', 'green', 'orange']  # Adjust the colors as needed\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label='Class: {0} (AUC = {1:.2f})'.format(class_labels[i], roc_auc[i]))\n",
    "\n",
    "# Plot the random guessing line\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve of PolyPhen Prediction Classes')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My next goal is to analyze a continuous target variable as opposed to a categorical one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df_clean3 = df_clean.copy()\n",
    "\n",
    "# Step 1: Split dataset into predictors (X) and target variable (y)\n",
    "X = df_clean3.drop('CLASS', axis=1)\n",
    "y = df_clean3['CLASS']\n",
    "\n",
    "# Step 2: Encode categorical variables if needed\n",
    "\n",
    "# Step 3: Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Create logistic regression model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Step 5: Fit the model to the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Make predictions on the testing data\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Step 7: Evaluate the performance of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Split dataset into predictors (X) and target variable (y)\n",
    "X = df_clean3.drop('CLASS', axis=1)\n",
    "y = df_clean3['CLASS']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the feature matrix\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create and fit the Lasso regression model\n",
    "lasso = Lasso(alpha=0.01)  # Adjust the alpha parameter as needed\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the coefficients\n",
    "coefficients = lasso.coef_\n",
    "\n",
    "# Identify selected features with non-zero coefficients\n",
    "selected_features = X.columns[coefficients != 0]\n",
    "\n",
    "# Print the selected features\n",
    "print(\"Selected Features:\")\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use selected features for logistic regression\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "# Create and fit the logistic regression model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_selected, y_train)\n",
    "\n",
    "# Predict the target variable for the test set\n",
    "y_pred = logreg.predict(X_test_selected)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[selected_features], y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and fit the Random Forest classifier\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[selected_features], y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Add interaction terms using PolynomialFeatures\n",
    "poly = PolynomialFeatures(interaction_only=True, include_bias=False)\n",
    "X_train_interactions = poly.fit_transform(X_train)\n",
    "X_test_interactions = poly.transform(X_test)\n",
    "\n",
    "# Create and fit the logistic regression model with interaction terms\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_interactions, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_logreg = logreg.predict(X_test_interactions)\n",
    "\n",
    "# Calculate the accuracy of logistic regression model\n",
    "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_logreg)\n",
    "\n",
    "# Create and fit the Random Forest classifier with interaction terms\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest.fit(X_train_interactions, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf = random_forest.predict(X_test_interactions)\n",
    "\n",
    "# Calculate the accuracy of Random Forest classifier\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Random Forest Accuracy:\", accuracy_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
